{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxRLoatwNhNG+gazZEBMhp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JMindpalace/Machine_Learning/blob/main/5.0%20%EB%AA%A8%EB%8D%B8%20%ED%95%99%EC%8A%B5%20%EB%B0%8F%20%EC%98%88%EC%B8%A1%2C%20%ED%8F%89%EA%B0%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "< 해당 페이지는 **머신러닝 - 모델의 설명과 학습, 예측과 평가**를 중점으로 다룬 페이지입니다.>\n",
        "\n",
        "> 크게 지도, 비지도, 강화 학습으로 분류되었으며<br>\n",
        "> 지도학습은 회귀와 분류로 중분류가 되어있고<br>\n",
        "\n",
        "> 주로 사용되는 모듈은 Sk-learn(머신러닝)과 keras(딥러닝)입니다.<br>\n",
        "> 딥러닝에는 tensorflow, pytorch도 가능합니다.\n",
        "\n",
        "> 기대 결과값: 일반화(Generalization, 테스트에 잘 적응하는 능력)가 잘되는 모델 선택<br>\n",
        "> 또한 모델의 과정을 이해하여 Black-box 문제도 해결"
      ],
      "metadata": {
        "id": "2xZqK6C_on-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learing(ML)"
      ],
      "metadata": {
        "id": "oKVEyL6KktN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ML 방향성"
      ],
      "metadata": {
        "id": "UAycJLvMkxY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 구분 및 주의사항, 파이프라인"
      ],
      "metadata": {
        "id": "28s8NKzLpb1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression # 선형회귀모델\n",
        "from sklearn.preprocessing import PolynomialFeatures # 선형회귀 - 다항선형모델\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score # 모델 성능 평가"
      ],
      "metadata": {
        "id": "LU8IzEl6s07Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train.fit_transform # 데이터 학습 - 훈련, 검증(Val) 데이터는 fit와 transform까지 가능함\n",
        "Test.transform      # 데이터 변환 - 테스트 데이터의 경우 무조건 transform만 시행함\n",
        "\n",
        "fit Attributes( 끝에 _가 붙은 메소드)"
      ],
      "metadata": {
        "id": "m6xpB9wx8uh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline(파이프라인) - 모델 계산을 위해 여러 번의 fit을 파이프라인으로 압축함\n",
        "make_pipeline(PolynomialFeatures(degree),\n",
        "              StandardScaler(),\n",
        "              LinearRegression(**kwargs))\n",
        "pipe = make_pipeline()\n",
        "pipe.fit(x,y)\n",
        "\n",
        "pipe.named_steps['linearregression'].coef_"
      ],
      "metadata": {
        "id": "MTvrI6stAdT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 지도(Supervised)-학습: 답(Target)을 아는 모델을 훈련하여 규칙 도출\n",
        "> Column 구분: 모델 학습은 Feature, label은 Target"
      ],
      "metadata": {
        "id": "BE3xv_Bcpenk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 회귀(Regression)모델: 계속적인 타겟(트렌드, 경향 등) 예측\n",
        "> 특성과 타겟의 선형적 관계(회귀계수로 표현)에서 최소 비용함수 찾기<BR>\n",
        "\n",
        "EX.) 예측\n",
        "1. 수명(Estimating Life Expectancy)\n",
        "2. 인구(Population Growth Prediction)\n",
        "3. 시장(Market Forecasting)\n",
        "4. 광고 인기(Advertising Popularity Prediction)\n",
        "5. 일기 예보(Weather Forecasting)"
      ],
      "metadata": {
        "id": "CnrDjpvTwemv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df.columns.drop('target'), df['target_data'] # int형"
      ],
      "metadata": {
        "id": "7S27yu5qMlhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. 기준 모델 - 예측 모델을 판단(하한선)기준\n",
        "predict = y_train[target].mean() # 회귀는 평균값 - 예측모델과 보간/외삽 비교에 사용\n",
        "base = predict * len(y_train)    # 기준모델 - 모델 성능 평가의 기준\n",
        "# 기준모델 평가는 ( y_train, base )"
      ],
      "metadata": {
        "id": "1MY0i9OnjxaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "# 1. 예측 모델 - 선형(Linear) 회귀 모델(비용함수 RSS의 잔차를 최소로하는 OLS)\n",
        "# 단순 선형: X값은 df['1_feature']\n",
        "simple_ols = LinearRegression()\n",
        "simple_ols.fit(X,y)\n",
        "\n",
        "# 다중 선형: X값은 2개 이상 - df[ '1_feature' , '2_feature' ]\n",
        "multiple_ols = LinearRegression()\n",
        "multiple_ols.fit(X, y)\n",
        "\n",
        "# 다항 선형 회귀: 2차항(degree로 최고차항 조정) 이상의 식 - 독립&타겟 변수 사이에 비선형 관계 학습 가능\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "def PolynomialRegression(degree=2, **kwargs):\n",
        "    return make_pipeline(PolynomialFeatures(degree), LinearRegression(**kwargs))\n",
        "\n",
        "poly_ols = PolynomialRegression(degree=2)\n",
        "poly_ols.fit(X, y)"
      ],
      "metadata": {
        "id": "SyDeIaf_j8cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 예측 모델의 예측값: 보간(Interploate, 학습구간 내) 과 외삽(Extrapolate, 학습구간 외)\n",
        "simp_predict = simple_ols.predict([[예측값]])[0]               # 단순 선형\n",
        "mult_predict = multiple_ols.predict([[ 예측값x, 예측값y ]])[0] # 다중 선형\n",
        "poly_predict = poly_ols.predict([[ 예측값x, 예측값y ]])[0]     # 다항 선형"
      ],
      "metadata": {
        "id": "82l-0qKQkBdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 회귀 모델 성능 평가\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "mse = mean_squared_error( 예측모델의 예측값 , y ) # MSE(Mean Squared Error): (실제값-예측값)제곱\n",
        "np.sqrt(mse)                                      # RMSE(Root MSE)\n",
        "mean_absolute_error( 예측모델의 예측값 , y )      # MAE(Mean Absolute Error): |실제값-예측값|\n",
        "r2_score( 예측모델의 예측값 , y )                 # R-Squared(Coefficient of determination): 1일수록 높은 설명력\n",
        "\n",
        "RMSLE(Root Mean Squared Log Error)\n",
        "\n",
        "# 빠른 R2 점수 출력\n",
        "from sklearn.model_selection import cross_val_score\n",
        "print_score(model, X_fit&transform_train, y_train, x_fit_test, y_test )"
      ],
      "metadata": {
        "id": "dr402s9TkNj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 모델 해석(추론) - coef(상관계수, 상관계수 1증가마다 타겟의 증가량)와 intercept(절편- 해석 없음)\n",
        "simple_ols.coef_   / simple_ols.intercept_\n",
        "multiple_ols.coef_ / multiple_ols.intercept_\n",
        "poly_ols.coef_     / poly_ols.intercept_"
      ],
      "metadata": {
        "id": "87i9rNGIkQ5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2e_cGhKallYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 분류(Classification)모델: 카테고리/클래스 예측\n",
        "> 이진(Binary) / 다중(Multi-class) 분류 등 특정 범주에 속할 확률 예측<BR>\n",
        "\n",
        "EX.)\n",
        "1. 고객 관리(Customer Retention)\n",
        "2. 진단(Diagnostics)\n",
        "3. 이미지 분류(Image Classification)\n",
        "4. 사기 탐지(Identity Fraud Detection)"
      ],
      "metadata": {
        "id": "uFVSTBbRwfmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필수: 분류문제는 타겟의 범주 비율을 우선 확인\n",
        "y = df['target']; y.value_counts(normalize=True);\n",
        "%matplotlib inline; sns.countplot(x=y);"
      ],
      "metadata": {
        "id": "PL-xUiyq7JcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 로지스틱회귀(Logistic Regression)\n",
        "> sklearn에서는 L2 패널티가 자동 적용되어 표준화 필수"
      ],
      "metadata": {
        "id": "e8uzKHONGzTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. 기준모델 - 분류면 타겟의 최빈 클래스 / 시계열이면 타임스탬프의 값\n",
        "base = y_train.mode()[0]\n",
        "base_pred = [base] * len(y_train)"
      ],
      "metadata": {
        "id": "TPM5HD4J-sfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 예측모델 - 로지스틱회귀sigmoid+선형회귀): 0~1사이의 값\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(class_weight='balanced') ) # 파라미터는 클래스별 가중치 적용\n",
        "lr.fit(X, y)\n",
        "\n",
        "lr.coef_ # 로지스틱 회귀계수 - 양수일수록 1, 음수일수록 0일 확률이 각각 높아짐, 영향력은 절댓값\n",
        "lr.feature_names_in_"
      ],
      "metadata": {
        "id": "gK73zNef-ysk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 예측 모델의 예측값\n",
        "pred = lr.predict( X )\n",
        "pred = lr.predict_proba( x )[:,1]"
      ],
      "metadata": {
        "id": "yScfygw2-175"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 모델 성능 평가 - 레이블을 올바르게 학습했는지 정밀도로 검증\n",
        "# 정확도(Accuracy) = 올바른 예측/전체 예측\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score( y_train, predict )\n",
        "\n",
        "# 정밀도(Precision) = 올바른 Positive 예측 / 예측 Positive(T+F) - 재현율과 반비례 관계\n",
        "# 재현율(Recall) = 올바른 Positive 예측 / 실제 Positive\n",
        "# F1 score = (2*정밀도) / (정밀도+재현율)\n",
        "\n",
        "# Confusion Matrix(혼동&오차행렬): 예측값과 실제 결과를 표시한 테이블\n"
      ],
      "metadata": {
        "id": "HHZxmmSg-4o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 예측(모델이 예측하는 확률)값을 평가하는 지표\n",
        "# ROC(Receiver Operating Characteristic): 임계값의 TPR, FPR의 비율\n",
        "# TPR = TP/P = TP/TP+FN = 1-FNR , 임계값이 1이면 TPR&FPR 모두 0\n",
        "# FPR = FP/N = FP/FP+TN = 1-TNR , 임계값이 0이면 TPR&FPR 모두 1\n",
        "\n",
        "# AUC(Area Under the Curve): ROC 곡선 아래면적, 1일수록 좋은 모델"
      ],
      "metadata": {
        "id": "z94HBFQ9CHPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 회귀&분류 공통 모델\n",
        "> 결정트리(Tree Based Model)<br>\n",
        "> 타겟: (분류는 최빈값, 회귀는 평균)의 예측값"
      ],
      "metadata": {
        "id": "5pcVsHrKwre3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 결정트리(Decision Tree): 비용함수(분류는 불순도 / 회귀는 MSE)에 따라 분기\n",
        "\n",
        "# Imformation Gain(엔트로피)\n",
        "\n",
        "# Gini Impurity(지니불순도)\n",
        "\n",
        "# 모델 해석은 시각화와 특성중요도"
      ],
      "metadata": {
        "id": "Zc6J9ZdkwnlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 앙상블 중 Bagging: Boot-strapped(OOB, 추출안된 샘플) > 분기(일부 랜덤 특성 선택) > 앞의 2과정 반복(독립&병렬적)\n",
        "# 랜덤-포레스트(Random-Forest): 분류는 다수결, 회귀는 평균의 전체 결과를 집계(Var를 줄여 과적합 해결)"
      ],
      "metadata": {
        "id": "kcAEt8r3Hfjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 앙상블 중 Boosting: 이전 모델의 오류를 보완하며 순차적 모델 학습(Bias를 줄여 과소적합 해결)\n",
        "# AdaBoost: 분류문제에 적합, 이상치에 민감, 샘플링 후 잘못 분류된 관측치에 가중치를 부여하여 다음 샘플링에 반영\n",
        "\n",
        "# Gradient Boosting: 회귀&분류 모두 적합, 잔차를 학습하여 잔차를 줄이는 방식"
      ],
      "metadata": {
        "id": "K5r3SCkCHlbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6fFkKfybpkFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 비지도(Un-supervised)-학습: 답이 없는 데이터 구조나 패턴 탐색\n",
        "> 특징/패턴 도출 등(지도학습의 전처리에도 사용 가능)"
      ],
      "metadata": {
        "id": "kmPY9KyppgHd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clustering(클러스터링): 비슷한 성질의 데이터끼리 그룹화<BR>\n",
        "\n",
        "EX.) \n",
        "1. 타겟 마케팅(Target Marketing)\n",
        "2. 고객 세분화(Customer Segmentation)\n",
        "3. 추천 시스템(Recommender Systems)"
      ],
      "metadata": {
        "id": "3zvayxWd_glT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 중요 포인트 1. 그룹의 수"
      ],
      "metadata": {
        "id": "zw38eEpH_np9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 중요 포인트 2. 유사도의 정의"
      ],
      "metadata": {
        "id": "D1s_2WnJ_6gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Elbow method : 최적의 클러스터 개수 찾기"
      ],
      "metadata": {
        "id": "XkdMpMJ8ACAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 차원 축소(Dimensionality Reduction): 고차원 데이터셋의 차원 감소\n",
        "> 차원의 저주(The Curse of Dimensionality) 해소<br>\n",
        "> (복잡한 시각화, 시간적 비효율성, 과적합 해소)<br>\n",
        "> 단, 정보손실은 최소화하면서 중요한 변수만 선택\n",
        "\n",
        "EX.) \n",
        "1. 특징 도출(Feature Elicitation)\n",
        "2. 의미 압축(Meaningful Compression)\n",
        "3. 빅데이터 시각화(BigData Visualization)\n",
        "4. 구조 분석(Structure Discovery)\n",
        "\n"
      ],
      "metadata": {
        "id": "Rg2uR1eCm7ly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Feature Selection\n",
        "> 덜 중요한 Feature 제거하여 선택된 소수 Feature의 직접 고려한 연관성으로 쉬운 해석"
      ],
      "metadata": {
        "id": "aFsHtiaPrRNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Feature Extraction\n",
        "> 기존 Feature의 상관관계를 고려하여 선형결합으로 조합, 어려운 해석"
      ],
      "metadata": {
        "id": "N0VqpvpMrSbL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### PCA: 기존 데이터를 최대한 보존(넓은 분산)하는 새로운 축(PC)에 사영(Linear Projection)하는 저차원 변환 기법\n",
        "> PC의 단위벡터는 데이터 공분산행렬의 Eigen-Vector<br>\n",
        "> Eigen-Vector에 사영한 분산이 Eigen-Value / 값은 기존 데이터 ⊥ Eigen-Vector"
      ],
      "metadata": {
        "id": "etITWUY-vMu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA 1. 데이터 표준화(전처리 StandardScaler 참고)\n",
        "# PCA 2. 공분산행렬 구하기 - matrix = np.cov(data.T)\n",
        "# PCA 3. 공분산행렬 Eigen-Stuff 구하기 - values, vectors = np.linalg.eig( matrix )\n",
        "# PCA 4. Eigen-Vector에 사영하기\n",
        "np.matmul( matrix, vectors ) # 행 단위는 np.dot( matrix[n행] , vectors[: , n행] )\n",
        "\n",
        "# PCA로 변환된 데이터 중 원하는 차원 선택으로 차원 축소 시행"
      ],
      "metadata": {
        "id": "e5zOphi7uqQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sklean PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "scale = StandardScaler() # 1. 표준화\n",
        "Z = scale.fit_transform( X )\n",
        "\n",
        "pca = PCA() # 2~3. PCA\n",
        "pca.fit(Z)\n",
        "pca.components_ # Eigen-vectors\n",
        "pca.explained_variance_ # Eigen-values\n",
        "\n",
        "pca.tarnsform(Z) # 4. PCA"
      ],
      "metadata": {
        "id": "thcjUSTj1_IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA Plot - Explained Variance(Eigen-Value) or Explained Variance Ratio로 주성분의 중요도 표시\n",
        "def pca_plot(pca):\n",
        "  val = pca.explained_variance_ratio_ # 분산 비율\n",
        "  num_components = len( val ) # 분산 길이\n",
        "  ind = np.arange(num_components) # [0 ~ 분산 길이] 분산 수\n",
        "\n",
        "  ax, cumvals = plt.subplot(), np.cumsum(vals) # 그래프, 누적 합\n",
        "  ax.bar(ind, val ) # X = 분산 수 , Y = 분산 비율\n",
        "  ax.plot(ind, cumvals ) # X = 분산 수 , Y = 누적 분산\n",
        "\n",
        "  for i in range(num_components):\n",
        "    ax.anootate(r\"%s\" % (( str(val[i]*100)[:3])), # 분산 값 3자리 문자열 형식\n",
        "                (ind[i] , val[i]) # 분산 위치\n",
        "                va = 'bottom', ha = 'center', fontsize = 13)\n",
        "\n",
        "pca_plot(pca)"
      ],
      "metadata": {
        "id": "oxowgmCJ20D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 연관 규칙 학습(Association Rule Learning): If-Then 형식으로 찾아가는 rule-based 방식\n",
        "> 데이터셋간의 Item 간(Feature-Feature)의 관계"
      ],
      "metadata": {
        "id": "fGezHGJlqgDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "bUxF_9JhplDG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 강화(Reinforcment)-학습: 보상/패널티로 많은 보상을 획득할 전략으로 예측<BR>\n",
        "\n",
        "EX.) \n",
        "1. 실시간 결정(RealTime Decisions)\n",
        "2. 로봇 탐색(Robot Navigation)\n",
        "3. 학습 과제(Learning Tasks)\n",
        "4. 기술 습득(Skill Acquisition)\n",
        "5. 게임 AI(Game AI)"
      ],
      "metadata": {
        "id": "0umkmRhVpib2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "M_6TaLIJor54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 준지도(Semi-supervised)-학습<BR>\n",
        "\n",
        "EX.) \n",
        "1. 고객 세분화(Customer Segmentation)\n",
        "2. 타겟 마케팅(Targeted Marketing)\n",
        "3. 사이트 분류(Website Classificatioin)\n",
        "4. 얼굴 인식(Face Recognition)\n",
        "5. 음성 분석(Speech Analysis)\n"
      ],
      "metadata": {
        "id": "_4wkr8FIorSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FtqpLVk4ptEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이상감지(Anomaly Detection)<BR>\n",
        "\n",
        "EX.) \n",
        "1. 사이버 침입(Cyber Intrusion)\n",
        "2. 신용카드 사기(CreditCard Fraud)"
      ],
      "metadata": {
        "id": "vI1hUBqBoyRk"
      }
    }
  ]
}