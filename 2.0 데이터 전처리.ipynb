{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVcv+uQH9xBHIvF6TUfpo2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JMindpalace/Machine_Learning/blob/main/2.0%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%A0%84%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "< 해당 페이지는 **데이터 전처리** 과정을 담은 페이지입니다. >\n",
        "\n",
        "> 데이터 변경의 마지막 페이지이며, 분석을 위한 깔끔한 테이블을 만드는 것이 목적입니다.\n",
        "\n",
        "> 전처리는 크게 일반적, 전문적으로 구분했으며<br>\n",
        "> 추가적으로 인공지능에 필요한 전처리를 추가 했습니다."
      ],
      "metadata": {
        "id": "-OfZDq9mEmrf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리(Data Preprocessing, data wrangling)"
      ],
      "metadata": {
        "id": "5mZeNqufE5lB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리의 방향성\n",
        "\n",
        "- 품질적 문제해결 : 결측치, 이상치, 중복데이터 등 데이터 값 처리\n",
        "\n",
        "- 구조적 문제해결 : 변수의 열과 관측치의 행이 올바른 테이블 만들기<br>\n",
        "  - 국소적으로는 Tidy data조건을 만족하여 분리가 가능하고\n",
        "  - 전체적으로는 Untidy data조건을 만족하여 키 값을 기준으로 통합된 형태"
      ],
      "metadata": {
        "id": "kvs53BAFE-GS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HTIrWvUmjxxQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 일반적인 전처리\n",
        "> Columns 순서&이름 변경 , 데이터 타입 변경"
      ],
      "metadata": {
        "id": "JOv5PDUVO48S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Columns 순서&이름 변경"
      ],
      "metadata": {
        "id": "wwQyEIxePBl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns 순서 변경\n",
        "change_col = [ 'ind1', 'ind2' --- ]; df[change_col]\n",
        "\n",
        "# Columns 이름 변경\n",
        "df.add_prefix() .add_suffix() # 접두/미사 추가\n",
        "df.rename( {변경 전 : 변경 후} ,  inplace=True, axis='columns' ) # 이름 단수 변경\n",
        "df.columns = [ 변경 전 : 변경 후 ] # 이름 복수 변경"
      ],
      "metadata": {
        "id": "vIpG5I8PQYbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 타입 변경"
      ],
      "metadata": {
        "id": "bAydwv3WX1fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 타입 검색\n",
        "df.select_dtypes(include='data type').head() # include 대신 exclude 사용 시 제외할 타입\n",
        "df.select_dtypes( 'include = [data type, --- ] ').head() # 다중 데이터 타입 검색"
      ],
      "metadata": {
        "id": "EoUJ7RCpgAAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모두 같은 데이터 타입으로 일괄 변경\n",
        "df.columns.astype('data type')"
      ],
      "metadata": {
        "id": "zXzySiFUXzpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1열을 제외한  모두 같은 데이터 타입으로 변경  >> 해당 1열을 인덱스화 후 해제\n",
        "df.set_index('제외할 1열')\n",
        "df.astype('data type')\n",
        "df.reset_index(inplace = True) # 원본에 영향 - 인덱스 해제 후 새로운 인덱스 생성\n",
        "# reseut_index 원본 영향 없이 - drop(인덱스 열 삭제 여부) & append(기존 인덱스 삭제 여부) = True/False\n",
        "# 역순 정렬은  행: df.loc[::-1].reset_index  //  열: df.loc[: , ::-1]"
      ],
      "metadata": {
        "id": "8uXbHAnaYCxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 타입 변경 중 Nan이 있는 경우\n",
        "df.astype(df.columns, erros = 'coerce' )\n",
        "# 일괄 수치형 변환\n",
        "df.apply(pd.to_numeric, erros = 'coerce' )\n",
        "# 수치 -> 범주형으로 변환(bins는 describe로 4분위 구하기 등 , 레이블은 범위 - labels = ['a', 'b', 'c' --- ])\n",
        "pd.cut( x=df['레이블로 구분할 칼럼'], bins=bins, labels=labels )"
      ],
      "metadata": {
        "id": "-OufFZmLcZ-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "v_GEq_GfPihp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전문적인 전처리"
      ],
      "metadata": {
        "id": "_GMZWLlCPCd7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 세부(잘못된 값 등) 데이터 처리 - 품질적 문제 해결"
      ],
      "metadata": {
        "id": "HVy_6wzTPFVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 잘못된 값 확인\n",
        "df.isnull().sum() # null 갯수 출력 : '-' 등 무슨 값이라도 있다면 null로 인식하지 않음\n",
        "df[ df[col_name].isnull() ] # null 행 출력\n",
        "\n",
        "# 함수로 특정 값 확인\n",
        "import re\n",
        "def has_check(inputstring):\n",
        "  return bool( re.search('[_ , ! , . , \\d+' , inputstring) )\n",
        "df[ df.col_name.apply(has_check) ]"
      ],
      "metadata": {
        "id": "A0vx2CanQ5WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 값 변경\n",
        "\n",
        "# 1. 값 교체\n",
        "df.col_name.str.replace('a to','b') # b에 np.nan을 넣으면 Nan data 삽입, regex=True면 일부 같더라도 변경\n",
        "df.col_name.str[:범위].str.pad('범위까지 자릿수', fillchar='자릿수까지 비었다면 채울 내용')\n",
        "\n",
        "# 2. 값 대체 - df.fillna()로 같지만 파라미터가 다름\n",
        "(n or 'n') # 단일 값으로 대체\n",
        "(method = 'ffill' or 'pad' | 'bfill' or 'backfill') # 위/아래값으로 대체(대체 중 nan이면 nan으로 유지됨)\n",
        "# 위/아래값의 추가 파라미터 - limit=n : 채우는 횟수 제한\n",
        "( df.mean() ) # 평균 값으로 대체\n",
        "\n",
        "# 3. 값 제거\n",
        "df.dropna()\n",
        "df.col_name.str.strip('content') # 특정 값 제거\n",
        "\n",
        "# 4. 값 제외(특정 값만 제외)\n",
        "df[ df.col_name != 'content' ]\n",
        "\n",
        "# 5. 값 분리(마지막의 str은 split로 분리되는 2개의 데이터셋 모두에게 적용하기 위함)\n",
        "df['col_name'].str.split('sep_content', len).str"
      ],
      "metadata": {
        "id": "bkJyiPzHSRCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 구조(전체)적 데이터 처리 - 구조적 문제 해결"
      ],
      "metadata": {
        "id": "mDAFTevYPMbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['추가할 Col_name'] = array 변수 # 데이터셋에 프레임 추가\n",
        "df.drop( 'del_col_name', axis=1 )  # 데이터셋의 프레임 제거"
      ],
      "metadata": {
        "id": "2d1deJiQT-6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 분리\n",
        "df['new_col_name'] = df.sep_col.str.extract( '(\\d+)' ) # 정규표현식 분리\n",
        "pd.melt( df, id_vars=['col_name' , '구분 기준(분리되지 않을)이 될 칼럼'] ) # value_vars = '값 , var_name = '이름'"
      ],
      "metadata": {
        "id": "tM1PYYW3UR09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mhrNIW4wU0g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 중복(Duplicated) 처리"
      ],
      "metadata": {
        "id": "Q8_oy5ODPZ5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FhgEWNDgPhxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 인공지능 전처리"
      ],
      "metadata": {
        "id": "KyINvWnBPjJK"
      }
    }
  ]
}