{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8TX9IEE/vxrVcbF1Zkwpd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JMindpalace/Machine_Learning/blob/main/3.0%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "< 해당 페이지는 **특성(Feature)**을 파악하고, **특성 공학(Feature Engineering)**으로 증폭 혹은 축소 시키는 페이지입니다. >\n",
        "\n",
        "> 데이터 변경은 거의 없고, 모델링의 전처리로 특성공학이나 상관계수 등에 따라 줄이는 것이 목표입니다.\n",
        "\n",
        "> 기대 결과 값: 여러 특성 간의 상관관계를 말할 수 있습니다."
      ],
      "metadata": {
        "id": "6edv9a4-7-_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 분석(Data Analysis)"
      ],
      "metadata": {
        "id": "11Sfaz7x9_b-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 분석의 방향성\n",
        "\n",
        "- 지도학습적 목적 : 특성과 타겟의 관계를 파악\n",
        "\n",
        "- 비지도학습적 목적 : 특성간의 관계를 파악해서 예측 타겟 설정"
      ],
      "metadata": {
        "id": "NWXvUAlq9_hS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ox9zInOT-K1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터셋 분석"
      ],
      "metadata": {
        "id": "01P7OU8X-LYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 특정 조건 검색1\n",
        "df[ (df['col'] == 'condition') ] # []내에 ()와 &로 다중 조건 검색 가능\n",
        "\n",
        "# 특정 조건 검색2 - 쿼리문의 변수는 @로 가져와야함(@변수)\n",
        "df.query( ('col' == 'condition') ) # ()내에 ()와 and로 다중 조건 검색 가능\n",
        "\n",
        "# Groupby - mean()외에도 median() 등 사용 가능\n",
        "df.groupby('그룹 기준 칼럼').mean()['값을 볼 칼럼'] # [기준1, 기준2]로 대/중분류, [ [값1, 값2] ]로 다중 그룹\n",
        "# Groupby가 리스트 반환이지만, 기준 칼럼 뒤에 , as_index=False면 데이터 프레임으로 반환"
      ],
      "metadata": {
        "id": "8fFq3r-WA8_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "UmE4FH3c3f0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 과대적합 감소"
      ],
      "metadata": {
        "id": "JXv3eBs93jTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 하이퍼-파라미터 조정"
      ],
      "metadata": {
        "id": "zjVaucOJ3qA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wmRtC0Nv3sqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 특성 조정(Feature Importance) - 어떤 특성이 중요한가\n",
        "> 모델의 예측값(성능)에 대한 특성들의 중요도 확인<br>\n",
        "> 낮은 중요도는 Drop"
      ],
      "metadata": {
        "id": "NQrooOYk3tJF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MDI(Mean Decrease impurity)\n",
        "> 트리 기반 모델에서 사용, Specific Model"
      ],
      "metadata": {
        "id": "1JYnH0WS5oaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = make_pipeline( OrdinalEncoder(),RandomForestClassifier() )\n",
        "rf = pipe.named_steps['randomforestclassifier'] # rf로 파이프라인 속성에 접근\n",
        "importances = pd.Series(rf.feature_importances_, X_train.columns) # 특성 이름 , 특성 중요도\n",
        "importances.sort_values().plot.barh() # MDI 시각화"
      ],
      "metadata": {
        "id": "YOCqegwb3zAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단, MDI의 추가적인 단점은 트리기반이기에 Cardinality의 의존도가 높다는 점이다\n",
        "X_train.nunique().sort_values().plot.barh() # Cardinality 그래프화"
      ],
      "metadata": {
        "id": "OYa7oDAk7OcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drop-Column Importance\n",
        "> 모든 특성을 가진 모델(기준) - 특정 특성을 제거하고 재학습한 모델<br>\n",
        "> 평가 하락시 중요 특성으로 파악함, Agnostic Model"
      ],
      "metadata": {
        "id": "VtDbWAz_7sqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_score = pipe.score(X_test, y_test)\n",
        "\n",
        "dci = pd.Series(dtype=float)\n",
        "for i in features: # features는 target과 분리 시 사용\n",
        "  p = pipe()\n",
        "\n",
        "  p.fit(X_train.drop(columns=[i], axis=1), y_train) # 특성 1개 drop 후 모델 재학습 - 큰 단점\n",
        "  score_dropped = p.score(X_test.drop(columns=[i], axis=1), y_test) # 특성 1개 drop한 모델의 점수\n",
        "  dci[feature] = score - score_dropped\n",
        "\n",
        "dci.sort_values().plot.barh()"
      ],
      "metadata": {
        "id": "GDk1rZvS7wpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Permutation Importance(순열 중요도)\n",
        "> 기준모델에서 특성마다 노이즈를 주어 성능 감소폭 확인<br>\n",
        "> 모든 모델에서 적용이 가능함, Agnostic&Global Model"
      ],
      "metadata": {
        "id": "4_Mvggod-CYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pi, n_iter = pd.Series((dtype=float), 10 # 성능 확인 과정 반복 횟수\n",
        "\n",
        "for i in features:  # 노이즈를 줄 feature 선택\n",
        "  X_test_permed = X_test_copy() # 중첩에서 변수값 변경\n",
        "  scores_permutated = []\n",
        "\n",
        "  for _ in range(n_iter):\n",
        "    X_test_permed[i] = np.random.permutation(X_test_permed[i])\n",
        "    scores_permutated.append( pipe.score(X_test_permed, y_test) )\n",
        "  avg_score = np.mean(scores_permutated) # 성능들의 평균 점수\n",
        "  pi[features] = score - avg_score       # 성능 하락폭\n",
        "pi.sort_values().plot.barh()\n",
        "\n",
        "# eli5 라이브러리 사용\n",
        "permuter = PermutationImportance(\n",
        "    pipe.named_steps[\"randomforestclassifier\"],  # model\n",
        "    scoring=\"accuracy\", n_iter=10, random_state=2\n",
        ")\n",
        "X_test_eli5 = pipe[0].transform(X_test) # OrdinalEncoder 사용\n",
        "permuter.fit(X_test_eli5, y_test)\n",
        "\n",
        "feature_names = X_test.columns.tolist()\n",
        "pd.Series( permuter.feature_importances_, feature_names ).sort_values().plot.barh()\n",
        "\n",
        "eli5.show_weights( # 특성별 score\n",
        "    permuter,\n",
        "    top=None,  # top n 지정 가능, None 일 경우 모든 특성\n",
        "    feature_names=feature_names,  # list 형식\n",
        ")"
      ],
      "metadata": {
        "id": "qs5szIQLBwpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 특성 영향 - 특성이 관계에 어떻게 영향을 줬는가\n",
        "> 특성 변화에 따른 모델 예측의 변화\n",
        "\n",
        "> 부분 의존도?"
      ],
      "metadata": {
        "id": "bRO4Yiy6hSZa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ICE(Individual Conditional Expectation) Plot\n",
        "> 개별 특성 값의 변화에 따른 모델 예측 변화, Agnostic&Local Model"
      ],
      "metadata": {
        "id": "aZ7gqNg_re4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_iceplot_data(data, data_index, target_feature, target_feature_range):\n",
        "  change_data, results = data.iloc[[data_index]].copy(), []\n",
        "\n",
        "  for i in target_feature_range: # 타겟범위(range로 최소~최대 등)\n",
        "    change_data[target_feature] = i # 타겟 데이터 변경\n",
        "    pred_proba = model_name.predict_proba(change_data)[:,1] # 바뀐 데이터로부터 확률 예측\n",
        "    results.append(pred_proba.item())\n",
        "  results = np.array(results)\n",
        "  return target_feature_range, results-results[0] # 최소(0)를 기준으로 예측의 상대값(변화량을 보기 위함)\n",
        "\n",
        "for i in [0, 10, 100, 1000]: # 변화를 확인할 특성 데이터 행\n",
        "  plt.plot(*get_iceplot_data(\n",
        "      X_test_encoded, data_index, target_feature, target_feature_range\n",
        "  )) # 결과값은 모델의 예측값이고, 파란 범위는 신뢰구간"
      ],
      "metadata": {
        "id": "-LtrYTVertxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PDP(Partial Dependence Plots) - ICE의 평균\n",
        "> 특성 전체가 모델의 반응양상(어떻게 분석하고 이해하는지) 시각화<BR>\n",
        "\n",
        "< 해석 주의 - Agnostic&Global Model >\n",
        "> 특성간 독립성이 전제됨 - 강한 상관관계의 경우 비현실적인 예측을 함<br>(서로 다른 특성 샘플에 변화 타겟 값이 동일 분포로 가정함, 특성 값이 없다면 만들어서 예측)<br>\n",
        "> 특성 값의 분포 주의(특성 관계가 강하면 구분 불가능)"
      ],
      "metadata": {
        "id": "KpoNAgenubwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PDP 라이브러리 사용\n",
        "isolated = pdp_isolate(\n",
        "    model = model_naem,\n",
        "    dataset = X_encoded,\n",
        "    model_features = X_.columns,\n",
        "    feature = target_feature,\n",
        "    grid_type = 'percentile' # or equal\n",
        "    num_grid_poins = n # default = 10, x축 범주\n",
        "    # cust_grid_points = [-100, 0 , 100, 1000] # 특성값을 볼 지점 지정가능\n",
        ")\n",
        "pdp_plot(isolated,\n",
        "         feature_name = target_feature, # 타겟은 1개로 설정!\n",
        "         plot_line = True, # ICE Plot\n",
        "         frac_to_plot = 50, # int면 plot할 데이터 수 , float이면 전체 데이터 갯수 중 plotting할 데이터 수의 비율\n",
        "         # 선택 기준은 np.sample로 선택\n",
        "         plot_pts_dist = True\n",
        ")"
      ],
      "metadata": {
        "id": "-AXoFb_7vMNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PDP Heat-map > 예측값 자체를 반환\n",
        "interaction = pdp_interact(\n",
        "    model = model_naem,\n",
        "    dataset = X_encoded,\n",
        "    model_features = X_.columns,\n",
        "    feature = target_feature # 타겟이 2개로 설정!\n",
        "    # cust_grid_points = [ [], None ] # 첫번째 특성은 지정, 두번째 특성은 자동 grid\n",
        ")\n",
        "pdp_interact_plot(interaction, plot_type='grid', feature_name = target_feature)"
      ],
      "metadata": {
        "id": "glLI_Nhtwb1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PDP 범주형 타겟 - 학습 때 자동 수치형으로 인코딩 변환됨\n",
        "mappings = encoder.mapping # mappings시 학습 encoder로부터 특성들이 각 값이 어떤 수치로 매핑된지 확인 가능\n",
        "mapping_data = list(filter(lambda x: x['col'] == target_feature, mappings)) # 매핑에서 타겟 특성 1개 추출\n",
        "maps = mapping_data[0]['mapping']\n",
        "\n",
        "encoded_features = maps.values.tolist() # 인코딩된 수치형 값\n",
        "original_features = maps.index.tolist() # 원래 특성값\n",
        "\n",
        "pdp_plot(isolated, target_feature)\n",
        "plt.xticks(encoded_features, original_features, rotation=90)"
      ],
      "metadata": {
        "id": "Kg_YHNctw8n9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}